{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6722846",
   "metadata": {},
   "source": [
    "# ISLES 2022 Example\n",
    "This notebook serves as an example for generating predictions for submission to the ISLES 2022 challenge. We'll cover all aspects of dealing with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00915a1b",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "There are two tasks in ISLES 2022: multi- and single-channel segmentation. The single-channel task uses the ATLAS 2.0 dataset,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ed6f2",
   "metadata": {},
   "source": [
    "### Task 2: ATLAS 2.0\n",
    "\n",
    "We can use the `atlas` module provided with this notebook to download and reformat the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a4e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlas\n",
    "atlas.data_fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9201c",
   "metadata": {},
   "source": [
    "The data will take a few minutes to download. The resulting file is an encrypted archive; you will first need to decrypt it. You can do so by following the [instructions on the ATLAS 2.0 download page](http://fcon_1000.projects.nitrc.org/indi/retro/atlas_download.html). The following code will prompt you for a password and then decrypt the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84862d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, subprocess\n",
    "# Decrypt the data; prompt user for password\n",
    "subprocess.call(['openssl', 'aes-256-cbc', '-md', 'sha256', \n",
    "                 '-d', '-a', '-in',\n",
    "                 'ATLAS_R2.0_encrypted.tar.gz', '-out', 'ATLAS_R2.0.tar.gz',\n",
    "                 '-pass', f'pass:{getpass.getpass(\"Enter password\")}'])\n",
    " \n",
    "subprocess.call(['tar', '-xzf', 'ATLAS_R2.0.tar.gz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb8555",
   "metadata": {},
   "source": [
    "We should now have a directory called `ATLAS_2` in the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8643c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d412f2",
   "metadata": {},
   "source": [
    "The data distributed by INDI is not compatible with PyBIDS, but the `atlas` module can convert it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda8859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlas\n",
    "atlas.bidsify_indi_atlas('ATLAS_2/', 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabd1ed",
   "metadata": {},
   "source": [
    "The data is now split into two directories: `data/train` and `data/test`. Predictably, the `train` directory contains data with labels with which to train your model. The `test` directory is the set of images that your model will need to segment. The archive files you downloaded can now be safely deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879eaa0f",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0b241",
   "metadata": {},
   "source": [
    "To train your model, you'll need to load data samples that are matched with their targets. We provide a Python package for doing just that: [BIDSIO](https://github.com/npnl/bidsio). The following code will walk you through loading matched data. We recommend reading through the BIDSIO GitHub page for up-to-date explanations of the different fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f782053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bidsio\n",
    "bids_loader = bidsio.BIDSLoader(data_entities=[{'subject': '',\n",
    "                                               'session': '',\n",
    "                                               'suffix': 'T1w',\n",
    "                                               'space': 'MNI152NLin2009aSym'}],\n",
    "                                target_entities=[{'suffix': 'mask',\n",
    "                                                'label': 'L',\n",
    "                                                'desc': 'T1lesion'}],\n",
    "                                data_derivatives_names=['ATLAS'],\n",
    "                                target_derivatives_names=['ATLAS'],\n",
    "                                batch_size=2,\n",
    "                                root_dir='data/train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdf6ab",
   "metadata": {},
   "source": [
    "We'll examine a few properties of the loader. First, let's verify that we have the correct number of subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = bids_loader.load_sample(0)\n",
    "print(f'There are {len(bids_loader)} subjects in our dataset.')\n",
    "print(f'Every sample loads {len(tmp)} images.')\n",
    "print(f'Images have these dimensions: {bids_loader.data_shape}')\n",
    "print(f'Every batch will load {bids_loader.batch_size} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01552497",
   "metadata": {},
   "source": [
    "Our loader can also provide a generator to allow us to iterate through the dataset. The generator is accessed via the `load_batches` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05692e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in bids_loader.load_batches():\n",
    "    print(f'Our data has the shape {data.shape}')\n",
    "    print(f'Our target has the shape {target.shape}')\n",
    "    # Cast to library and transfer to desired device\n",
    "    # Train model\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb8f86",
   "metadata": {},
   "source": [
    "Note the dimensions of our data; they have been reshaped to be consistent with libraries such as PyTorch:  \n",
    "(Sample in batch, channel, X, Y, Z)  \n",
    "You can cast the arrays to the package of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadcf8ce",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Once your model is trained, you'll want to make predictions on the test data and upload them for evaluation. We expect the data to be formatted as a BIDS dataset. In this section, we'll show you how to easily format your predictions without having to go through the BIDS standard.  \n",
    "First, we'll load the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9fc7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bidsio\n",
    "bids_loader = bidsio.BIDSLoader(data_entities=[{'subject': '',\n",
    "                                               'session': '',\n",
    "                                               'suffix': 'T1w',\n",
    "                                               'space': 'MNI152NLin2009aSym'}],\n",
    "                                target_entities=[],\n",
    "                                data_derivatives_names=['ATLAS'],\n",
    "                                batch_size=4,\n",
    "                                root_dir='data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat, image_list in bids_loader.load_batch_for_prediction():\n",
    "    print(f'Data shape: {dat.shape}')\n",
    "    print(f'Example BIDS file: {image_list[0]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4abc2",
   "metadata": {},
   "source": [
    "You'll notice that we use a different generator for loading the predictions. This generator also yields the BIDS image file that stored the data. We'll create a new BIDS directory using this information.  \n",
    "First, we'll need to create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364e3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create great model.\n",
    "import numpy as np\n",
    "class some_model():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Simple model to serve as an example.\n",
    "        '''\n",
    "        return\n",
    "    \n",
    "    def predict(self, data: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Returns '1' for voxels whose value are greater than the image mean.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Data for which to make a prediction of the labels.\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Model prediction for the input data.\n",
    "    '''\n",
    "        data_mean = np.mean(data)\n",
    "        return np.array(data > data_mean, dtype=np.float32)\n",
    "your_model = some_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ba955",
   "metadata": {},
   "source": [
    "The `your_model` object will be used a stand-in for a fully-trained model.  \n",
    "As before, we'll use the `load_batch_for_prediction` method to obtain our data. We can write out our predictions as we generate them using the `write_image_like` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(bids_loader.write_image_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_dir = 'prediction_bids/'  # Directory where to write out predictions\n",
    "for dat, image_list in bids_loader.load_batch_for_prediction():\n",
    "    prediction = your_model.predict(dat)  # Make a prediction\n",
    "    # Reduce to set of 3D images\n",
    "    for i in range(prediction.shape[0]):  # Iterate through each sample in the batch\n",
    "        pred_out = prediction[i,0,...]\n",
    "        image_ref = image_list[i][0]\n",
    "        print(f\"Writing image for subject {image_ref.entities['subject']}\")\n",
    "        \n",
    "        bids_loader.write_image_like(data_to_write=pred_out,\n",
    "                                     image_to_imitate=image_ref,\n",
    "                                     new_bids_root=example_output_dir,\n",
    "                                     new_entities={'label': 'L',\n",
    "                                                   'suffix': 'mask'})\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24189f61",
   "metadata": {},
   "source": [
    "We see that we create a file for each subject present in our batch. Let's verify that the files were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57cc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for p, _, fnames in os.walk(example_output_dir):  # Walk through dir structure\n",
    "    if(len(fnames) > 0):\n",
    "        for f in fnames:\n",
    "            print(os.path.join(p, f))  # Print full path of files that are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502c77e",
   "metadata": {},
   "source": [
    "You should see one image for each sample in a batch, with `label-L` and `mask` inserted into the filename. BIDS requires one more file, `dataset_description.json`, which we can create with `write_dataset_description`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02220fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(bidsio.BIDSLoader.write_dataset_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidsio.BIDSLoader.write_dataset_description(bids_root=example_output_dir,\n",
    "                                            dataset_name='atlas2_prediction',\n",
    "                                            author_names=['Hutton, A.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dec972",
   "metadata": {},
   "source": [
    "We can then take a look at the JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843585b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "f = open(f'{example_output_dir}{os.sep}dataset_description.json')\n",
    "dataset_description = json.load(f)\n",
    "f.close()\n",
    "print(dataset_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe695ac",
   "metadata": {},
   "source": [
    "Our predictions are now a BIDS-compatible dataset and can be zipped and submitted to the Grand Challenge website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bids\n",
    "prediction_bids = bids.BIDSLayout(root=example_output_dir, derivatives=example_output_dir)\n",
    "print(prediction_bids.derivatives['atlas2_prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (isles_venv)",
   "language": "python",
   "name": "isles_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
