{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6722846",
   "metadata": {},
   "source": [
    "# ISLES 2022 Example\n",
    "This notebook serves as an example for generating predictions for submission to the ISLES 2022 challenge. We'll cover all aspects of dealing with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00915a1b",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "There are two tasks in ISLES 2022: multi- and single-channel segmentation. The single-channel task uses the ATLAS 2.0 dataset,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4141c",
   "metadata": {},
   "source": [
    "### Task 2: ATLAS 2.0\n",
    "\n",
    "We can use the `atlas` module provided with this notebook to download and reformat the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlas\n",
    "atlas.data_fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907c9ce",
   "metadata": {},
   "source": [
    "The data will take a few minutes to download. The resulting file is an encrypted archive; you will first need to decrypt it. You can do so by following the [instructions on the ATLAS 2.0 download page](http://fcon_1000.projects.nitrc.org/indi/retro/atlas_download.html). The following code will prompt you for a password and then decrypt the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, subprocess\n",
    "# Decrypt the data; prompt user for password\n",
    "subprocess.call(['openssl', 'aes-256-cbc', '-md', 'sha256', \n",
    "                 '-d', '-a', '-in',\n",
    "                 'ATLAS_R2.0_encrypted.tar.gz', '-out', 'ATLAS_R2.0.tar.gz',\n",
    "                 '-pass', f'pass:{getpass.getpass(\"Enter password\")}'])\n",
    " \n",
    "subprocess.call(['tar', '-xzf', 'ATLAS_R2.0.tar.gz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e46b82",
   "metadata": {},
   "source": [
    "We should now have a directory called `ATLAS_2` in the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c250004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320d72e",
   "metadata": {},
   "source": [
    "The data distributed by INDI is not compatible with PyBIDS, but the `atlas` module can convert it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import atlas\n",
    "atlas.bidsify_indi_atlas('ATLAS_2/', 'data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8846eb",
   "metadata": {},
   "source": [
    "The data is now split into two directories: `data/train` and `data/test`. Predictably, the `train` directory contains data with labels with which to train your model. The `test` directory is the set of images that your model will need to segment. The archive files you downloaded can now be safely deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee8039",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12412b96",
   "metadata": {},
   "source": [
    "To train your model, you'll need to load data samples that are matched with their targets. We provide a Python package for doing just that: [BIDSIO](https://github.com/npnl/bidsio). The following code will walk you through loading matched data. We recommend reading through the BIDSIO GitHub page for up-to-date explanations of the different fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bidsio\n",
    "bids_loader = bidsio.BIDSLoader(data_entities=[{'subject': '',\n",
    "                                               'session': '',\n",
    "                                               'suffix': 'T1w',\n",
    "                                               'space': 'MNI152NLin2009aSym'}],\n",
    "                                target_entities=[{'suffix': 'mask',\n",
    "                                                'label': 'L',\n",
    "                                                'desc': 'T1lesion'}],\n",
    "                                data_derivatives_names=['ATLAS'],\n",
    "                                target_derivatives_names=['ATLAS'],\n",
    "                                batch_size=2,\n",
    "                                root_dir='data/train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0565f1a",
   "metadata": {},
   "source": [
    "We'll examine a few properties of the loader. First, let's verify that we have the correct number of subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = bids_loader.load_sample(0)\n",
    "print(f'There are {len(bids_loader)} subjects in our dataset.')\n",
    "print(f'Every sample loads {len(tmp)} images.')\n",
    "print(f'Images have the dimensions: {bids_loader.data_shape}')\n",
    "print(f'Every batch will load {bids_loader.batch_size} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f15de",
   "metadata": {},
   "source": [
    "Our loader can also provide a generator to allow us to iterate through the dataset. The generator is accessed via the `load_batches` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in bids_loader.load_batches():\n",
    "    print(f'Our data has the shape {data.shape}')\n",
    "    print(f'Our target has the shape {target.shape}')\n",
    "    # Cast to library and transfer to desired device\n",
    "    # Train model\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e3a6b",
   "metadata": {},
   "source": [
    "Note the dimensions of our data; they have been reshaped to be consistent with libraries such as PyTorch:  \n",
    "(Sample in batch, channel, X, Y, Z)  \n",
    "You can cast the arrays to the package of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7220058",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Once your model is trained, you'll want to make predictions on the test data and upload them for evaluation. We expect the data to be formatted as a BIDS dataset. In this section, we'll show you how to easily format your predictions without having to go through the BIDS standard.  \n",
    "First, we'll load the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0e3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bidsio\n",
    "bids_loader = bidsio.BIDSLoader(data_entities=[{'subject': '',\n",
    "                                               'session': '',\n",
    "                                               'suffix': 'T1w',\n",
    "                                               'space': 'MNI152NLin2009aSym'}],\n",
    "                                target_entities=[],\n",
    "                                data_derivatives_names=['ATLAS'],\n",
    "                                batch_size=4,\n",
    "                                root_dir='data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cef9823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4, 1, 197, 233, 189)\n",
      "Example BIDS file: (<BIDSImageFile filename='/home/lex/NPNL/projects/isles_tutorial/ISLES_tutorial/data/test/derivatives/ATLAS/sub-r005s016/ses-1/anat/sub-r005s016_ses-1_space-MNI152NLin2009aSym_T1w.nii.gz'>,)\n"
     ]
    }
   ],
   "source": [
    "for dat, image_list in bids_loader.load_batch_for_prediction():\n",
    "    print(f'Data shape: {dat.shape}')\n",
    "    print(f'Example BIDS file: {image_list[0]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba412a50",
   "metadata": {},
   "source": [
    "You'll notice that we use a different generator for loading the predictions. This generator also yields the BIDS image file that stored the data. We'll create a new BIDS directory using this information.  \n",
    "First, we'll need to create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d91813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create great model.\n",
    "import numpy as np\n",
    "class some_model():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Simple model to serve as an example.\n",
    "        '''\n",
    "        return\n",
    "    \n",
    "    def predict(self, data: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Returns '1' for voxels whose value are greater than the image mean.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Data for which to make a prediction of the labels.\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Model prediction for the input data.\n",
    "    '''\n",
    "        data_mean = np.mean(data)\n",
    "        return np.array(data > data_mean, dtype=np.float32)\n",
    "your_model = some_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80409b6b",
   "metadata": {},
   "source": [
    "The `your_model` object will be used a stand-in for a fully-trained model.  \n",
    "As before, we'll use the `load_batch_for_prediction` method to obtain our data. We can write out our predictions as we generate them using the `write_image_like` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c251f8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function write_image_like in module bidsio.bidsloader:\n",
      "\n",
      "write_image_like(data_to_write: <built-in function array>, image_to_imitate: bids.layout.models.BIDSImageFile, new_bids_root: str, new_entities: dict = None)\n",
      "    Writes an image to a different BIDS directory using the path pattern of an existing image. Optionally\n",
      "    inserts new entities and replaces existing values.\n",
      "    Parameters\n",
      "    ----------\n",
      "    data_to_write : np.array\n",
      "        Image data to save.\n",
      "    image_to_imitate : BIDSImageFile\n",
      "        Image with BIDS entities to imitate\n",
      "    new_bids_root : str\n",
      "        BIDS root to save image in.\n",
      "    new_entities : dict\n",
      "        Optional. Entity-value pairs to overwrite\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bids_loader.write_image_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8084aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing image for subject r005s016\n",
      "Writing image for subject r005s025\n",
      "Writing image for subject r005s030\n",
      "Writing image for subject r005s034\n"
     ]
    }
   ],
   "source": [
    "example_output_dir = 'prediction_bids/'  # Directory where to write out predictions\n",
    "for dat, image_list in bids_loader.load_batch_for_prediction():\n",
    "    prediction = your_model.predict(dat)  # Make a prediction\n",
    "    # Reduce to set of 3D images\n",
    "    for i in range(prediction.shape[0]):  # Iterate through each sample in the batch\n",
    "        pred_out = prediction[i,0,...]\n",
    "        image_ref = image_list[i][0]\n",
    "        print(f\"Writing image for subject {image_ref.entities['subject']}\")\n",
    "        \n",
    "        bids_loader.write_image_like(data_to_write=pred_out,\n",
    "                                     image_to_imitate=image_ref,\n",
    "                                     new_bids_root=example_output_dir,\n",
    "                                     new_entities={'label': 'L',\n",
    "                                                   'suffix': 'mask'})\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb31f6",
   "metadata": {},
   "source": [
    "We see that we create a file for each subject present in our batch. Let's verify that the files were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d2148a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_bids/sub-r005s016/ses-1/anat/sub-r005s016_ses-1_space-MNI152NLin2009aSym_label-L_mask.nii.gz\n",
      "prediction_bids/sub-r005s034/ses-1/anat/sub-r005s034_ses-1_space-MNI152NLin2009aSym_label-L_mask.nii.gz\n",
      "prediction_bids/sub-r005s025/ses-1/anat/sub-r005s025_ses-1_space-MNI152NLin2009aSym_label-L_mask.nii.gz\n",
      "prediction_bids/sub-r005s030/ses-1/anat/sub-r005s030_ses-1_space-MNI152NLin2009aSym_label-L_mask.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for p, _, fnames in os.walk(example_output_dir):  # Walk through dir structure\n",
    "    if(len(fnames) > 0):\n",
    "        for f in fnames:\n",
    "            print(os.path.join(p, f))  # Print full path of files that are found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595c49b",
   "metadata": {},
   "source": [
    "You should see one image for each sample in a batch, with `label-L` and `mask` inserted into the filename. BIDS requires one more file, `dataset_description.json`, which we can create with `write_dataset_description`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28ec8484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function write_dataset_description in module bidsio.bidsloader:\n",
      "\n",
      "write_dataset_description(bids_root: str, dataset_name: str, author_names: list = None, derivative_name: str = None, derivative_version: str = '1.0')\n",
      "    Writes the dataset_description.json file to the BIDS root.\n",
      "    Parameters\n",
      "    ----------\n",
      "    bids_root : str\n",
      "        Path to the BIDS data root directory.\n",
      "    dataset_name : str\n",
      "        Name to enter for the various \"Name\" fields in `dataset_description.json`\n",
      "    author_names : list\n",
      "        Optional. List of authors.\n",
      "    derivative_name : str\n",
      "        Optional. If not None, write to the `derivatives/derivative_name/` directory instead of the root directory.\n",
      "    derivative_version : str\n",
      "        Optional. Version of the pipeline used to generate.\n",
      "    Returns\n",
      "    -------\n",
      "    None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(bidsio.BIDSLoader.write_dataset_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e183538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidsio.BIDSLoader.write_dataset_description(bids_root=example_output_dir,\n",
    "                                            dataset_name='atlas2_prediction',\n",
    "                                            author_names=['Hutton, A.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9be56",
   "metadata": {},
   "source": [
    "We can then take a look at the JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27635f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'atlas2_prediction', 'BIDSVersion': '1.6.0', 'Authors': ['Hutton, A.'], 'PipelineDescription': {'Name': 'atlas2_prediction'}, 'GeneratedBy': [{'Name': 'atlas2_prediction', 'Version': '1.0'}]}\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "f = open(f'{example_output_dir}{os.sep}dataset_description.json')\n",
    "dataset_description = json.load(f)\n",
    "f.close()\n",
    "print(dataset_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bbcd61",
   "metadata": {},
   "source": [
    "Our predictions are now a BIDS-compatible dataset and can be submitted to the GC website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33c46965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIDS Layout: ...ISLES_tutorial/prediction_bids | Subjects: 4 | Sessions: 4 | Runs: 0\n"
     ]
    }
   ],
   "source": [
    "import bids\n",
    "prediction_bids = bids.BIDSLayout(root=example_output_dir, derivatives=example_output_dir)\n",
    "print(prediction_bids.derivatives['atlas2_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07942bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (isles_venv)",
   "language": "python",
   "name": "isles_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
